{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train for 50 epochs on the combined dataset, then fine-tune on CK+ for 15 epochs\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, ConcatDataset, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "img_transforms = transforms.Compose([\n",
    "    transforms.Resize((48, 48)),\n",
    "    transforms.RandomResizedCrop((40, 40)),\n",
    "    transforms.Grayscale(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "class GradientReversalFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, lambda_val):\n",
    "        ctx.lambda_val = lambda_val\n",
    "        return x.view_as(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return grad_output.neg() * ctx.lambda_val, None\n",
    "\n",
    "class GradientReversalLayer(nn.Module):\n",
    "    def __init__(self, lambda_val=1.0):\n",
    "        super(GradientReversalLayer, self).__init__()\n",
    "        self.lambda_val = lambda_val\n",
    "\n",
    "    def forward(self, x):\n",
    "        return GradientReversalFunction.apply(x, self.lambda_val)\n",
    "\n",
    "class VGG19EmotionCNN(nn.Module):\n",
    "    def __init__(self, num_classes, lambda_val=1.0):\n",
    "        super(VGG19EmotionCNN, self).__init__()\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.conv_block3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.conv_block4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.conv_block5 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.fc1 = nn.Linear(512, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 4096)\n",
    "        self.fc3 = nn.Linear(4096, num_classes)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.grl = GradientReversalLayer(lambda_val)\n",
    "        self.domain_classifier = nn.Sequential(\n",
    "            nn.Linear(4096, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = self.conv_block3(x)\n",
    "        x = self.conv_block4(x)\n",
    "        x = self.conv_block5(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(nn.ReLU()(self.fc1(x)))\n",
    "        x = self.dropout(nn.ReLU()(self.fc2(x)))\n",
    "        emotion_output = self.fc3(x)\n",
    "        domain_output = self.domain_classifier(self.grl(x))\n",
    "        return emotion_output, domain_output\n",
    "\n",
    "\n",
    "class DataWrapper(Dataset):\n",
    "    def __init__(self, data, domain):\n",
    "        self.data = data\n",
    "        self.domain = domain\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.data[idx]\n",
    "        return x, y, self.domain\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "data_a = DataWrapper(\n",
    "    datasets.ImageFolder(root='./datasets/fer2013', transform=img_transforms),\n",
    "    domain=0\n",
    ")\n",
    "\n",
    "data_b = DataWrapper(\n",
    "    datasets.ImageFolder(root='./datasets/raf-db/train', transform=img_transforms),\n",
    "    domain=1\n",
    ")\n",
    "\n",
    "combined_data = ConcatDataset([data_a, data_b])\n",
    "\n",
    "data_loader = DataLoader(\n",
    "    combined_data,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "num_classes = len(data_b.data.classes)\n",
    "network = VGG19EmotionCNN(num_classes)\n",
    "loss_fn1 = nn.CrossEntropyLoss()\n",
    "loss_fn2 = nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer_config = optim.SGD(network.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0001, nesterov=True)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer_config, mode='min', factor=0.5, patience=4)\n",
    "\n",
    "epochs = 50\n",
    "device_type = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "network = network.to(device_type)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    network.train()\n",
    "    total_cycle_loss = 0\n",
    "\n",
    "    for batch in data_loader:\n",
    "        imgs, lbls, doms = batch\n",
    "        \n",
    "        imgs = imgs.to(device_type)\n",
    "        lbls = lbls.to(device_type)\n",
    "        doms = doms.float().unsqueeze(1).to(device_type)\n",
    "       \n",
    "        optimizer_config.zero_grad()\n",
    "\n",
    "        emo_out, dom_out = network(imgs)\n",
    "  \n",
    "        emo_loss = loss_fn1(emo_out, lbls)\n",
    "        dom_loss = loss_fn2(dom_out, doms)\n",
    "    \n",
    "        lambda_factor = 0.05\n",
    "        combined_loss = emo_loss + lambda_factor * dom_loss\n",
    "\n",
    "        combined_loss.backward()\n",
    "        optimizer_config.step()\n",
    " \n",
    "        total_cycle_loss += combined_loss.item()\n",
    "    curr_lr = optimizer_config.param_groups[0]['lr']\n",
    "    lr_scheduler.step(total_cycle_loss / len(data_loader))\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, lr:{curr_lr:.4f}\\tLoss: {total_cycle_loss / len(data_loader):.4f}\")\n",
    "\n",
    "save_file = './modelsAll/DANN32_50.pth'\n",
    "torch.save({\n",
    "    'model_state_dict': network.state_dict(),\n",
    "    'optimizer_state_dict': optimizer_config.state_dict(),\n",
    "    'scheduler_state_dict': lr_scheduler.state_dict(),\n",
    "}, save_file)\n",
    "\n",
    "print(\"Model DANN32_50 saved\")\n",
    "\n",
    "load_file = './modelsAll/DANN32_50.pth'\n",
    "loaded_data = torch.load(load_file, map_location=device_type)\n",
    "network.load_state_dict(loaded_data['model_state_dict'])\n",
    "network = network.to(device_type)\n",
    "network.train()\n",
    "\n",
    "new_data = datasets.ImageFolder(root='./datasets/CK+48', transform=img_transforms)\n",
    "new_loader = DataLoader(new_data, batch_size=32, shuffle=True)\n",
    "\n",
    "optimizer_config = optim.SGD(network.parameters(), lr=0.005, momentum=0.9, weight_decay=0.0001, nesterov=True)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer_config, mode='min', factor=0.5, patience=4)\n",
    "\n",
    "loss_fn1 = nn.CrossEntropyLoss()\n",
    "\n",
    "fine_tune_epochs = 15\n",
    "for epoch in range(fine_tune_epochs):\n",
    "    network.train()\n",
    "    total_tune_loss = 0\n",
    "\n",
    "    for batch in new_loader:\n",
    "        imgs, lbls = batch\n",
    "        imgs = imgs.to(device_type)\n",
    "        lbls = lbls.to(device_type)\n",
    "\n",
    "        optimizer_config.zero_grad()\n",
    "\n",
    "        emo_out, _ = network(imgs)\n",
    "\n",
    "        loss = loss_fn1(emo_out, lbls)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer_config.step()\n",
    "\n",
    "        total_tune_loss += loss.item()\n",
    "    \n",
    "    curr_lr = optimizer_config.param_groups[0]['lr']\n",
    "    lr_scheduler.step(total_tune_loss / len(new_loader))\n",
    "    print(f\"Epoch {epoch+1}/{fine_tune_epochs}, lr:{curr_lr:.4f}, Loss: {total_tune_loss / len(new_loader):.4f}\")\n",
    "\n",
    "fine_tune_save = './modelsAll/DANN32.2_fine_tuned.pth'\n",
    "torch.save({\n",
    "    'model_state_dict': network.state_dict(),\n",
    "    'optimizer_state_dict': optimizer_config.state_dict(),\n",
    "    'scheduler_state_dict': lr_scheduler.state_dict(),\n",
    "}, fine_tune_save)\n",
    "\n",
    "print(\"Model DANN32.2_fine_tuned.pth saved\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
